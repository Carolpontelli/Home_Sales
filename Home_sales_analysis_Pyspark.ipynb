{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Carolpontelli/Home_Sales/blob/main/Home_sales_analysis_Pyspark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwgNuXkcMMVt",
        "outputId": "3f3c2a0e-d361-4550-a425-0c1fbf6f6d6c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425344 sha256=c129abb34dadfc50ba05396ca33f0afc8c02d34d92abb68cbcc39cc278369d6d\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import packages\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkFiles\n",
        "import time\n",
        "from pyspark.sql.functions import year, round\n",
        "import time"
      ],
      "metadata": {
        "id": "9VoyYmjCTNvW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a SparkSession\n",
        "spark = SparkSession.builder.appName(\"SparkSQL\").getOrCreate()\n",
        "\n",
        "\n",
        "# Read in the AWS S3 bucket into a DataFrame\n",
        "url = \"https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-classroom/v1.2/22-big-data/home_sales_revised.csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "df = spark.read.csv(\"file://\" + SparkFiles.get(\"home_sales_revised.csv\"), header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "5UHupM9RTQKk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract 'year' from the 'date' column\n",
        "df = df.withColumn(\"year\", year(\"date\"))"
      ],
      "metadata": {
        "id": "1-ayWRq9TSVJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a temporary table called home_sales\n",
        "df.createOrReplaceTempView(\"home_sales\")"
      ],
      "metadata": {
        "id": "iKBYn6knTSSj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exibir as colunas do DataFrame\n",
        "df_columns = df.columns\n",
        "print(df_columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-m9SdYVzHV4",
        "outputId": "73a76299-278b-4c78-947a-d1077f3024db"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['id', 'date', 'date_built', 'price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', 'year']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Query for average price of a four-bedroom house sold in each year\n",
        "query3 = \"SELECT year, ROUND(AVG(price), 2) as avg_price FROM home_sales WHERE bedrooms = 4 GROUP BY year\"\n",
        "result3 = spark.sql(query3)\n",
        "result3.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWlruexXTSKS",
        "outputId": "7e64c978-2b5b-4be6-921b-e30949fb9e63"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---------+\n",
            "|year|avg_price|\n",
            "+----+---------+\n",
            "|2022|296363.88|\n",
            "|2019| 300263.7|\n",
            "|2020|298353.78|\n",
            "|2021|301819.44|\n",
            "+----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Query for average price of a home with three bedrooms and three bathrooms\n",
        "query4 = \"SELECT year, ROUND(AVG(price), 2) as avg_price FROM home_sales WHERE bedrooms = 3 AND bathrooms = 3 GROUP BY year\"\n",
        "result4 = spark.sql(query4)\n",
        "result4.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3svcDtTTZSo",
        "outputId": "795881b6-14ae-4fb1-89c5-f38f52a4031c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---------+\n",
            "|year|avg_price|\n",
            "+----+---------+\n",
            "|2022|292725.69|\n",
            "|2019|287287.82|\n",
            "|2020|294204.16|\n",
            "|2021|294211.46|\n",
            "+----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Query for average price of a home with specific features for each year\n",
        "query5 = \"SELECT year, ROUND(AVG(price), 2) as avg_price FROM home_sales WHERE bedrooms = 3 AND bathrooms = 3 AND floors = 2 AND sqft_living >= 2000 GROUP BY year\"\n",
        "result5 = spark.sql(query5)\n",
        "result5.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8WYPSYZTcdy",
        "outputId": "f73bcee9-c174-422f-f0da-ab46876bd823"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---------+\n",
            "|year|avg_price|\n",
            "+----+---------+\n",
            "|2022|290242.99|\n",
            "|2019|289859.14|\n",
            "|2020|292289.09|\n",
            "|2021|296330.96|\n",
            "+----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Query for view rating for homes costing more than or equal to $350,000 with runtime\n",
        "start_time = time.time()\n",
        "query6 = \"SELECT view, ROUND(AVG(price), 2) as avg_price FROM home_sales WHERE price >= 350000 GROUP BY view\"\n",
        "result6 = spark.sql(query6)\n",
        "end_time = time.time()\n",
        "runtime_query6 = \"{:.2f}\".format(end_time - start_time)\n",
        "result6.show()\n",
        "print(f\"Runtime for query 6: {runtime_query6} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guI-dXFFic_0",
        "outputId": "e29ef61c-6600-448d-ae2b-f1e2f1a4d275"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----------+\n",
            "|view| avg_price|\n",
            "+----+----------+\n",
            "|  31| 399856.95|\n",
            "|  85|1056336.74|\n",
            "|  65| 736679.93|\n",
            "|  53|  755214.8|\n",
            "|  78|1080649.37|\n",
            "|  34| 401419.75|\n",
            "|  81|1053472.79|\n",
            "|  28| 402124.62|\n",
            "|  76|1058802.78|\n",
            "|  26| 401506.97|\n",
            "|  27| 399537.66|\n",
            "|  44| 400598.05|\n",
            "|  12| 401501.32|\n",
            "|  91|1137372.73|\n",
            "|  22| 402022.68|\n",
            "|  93|1026006.06|\n",
            "|  47|  398447.5|\n",
            "|   1| 401044.25|\n",
            "|  52| 733780.26|\n",
            "|  13| 398917.98|\n",
            "+----+----------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Runtime for query 6: 0.20 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Cache the temporary table home_sales\n",
        "spark.catalog.cacheTable(\"home_sales\")"
      ],
      "metadata": {
        "id": "yWu2ranAiMw0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Run the cached query and measure runtime\n",
        "start_time_cached = time.time()\n",
        "result_cached = spark.sql(query6)\n",
        "end_time_cached = time.time()\n",
        "runtime_cached = \"{:.2f}\".format(end_time_cached - start_time_cached)\n",
        "print(f\"Runtime for cached query: {runtime_cached} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0stagUNi5UM",
        "outputId": "185ffa4b-c868-4d8d-f0af-da7ed97fbaff"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Runtime for cached query: 0.06 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Partition by the \"date_built\" field on the formatted parquet home sales data\n",
        "df.write.partitionBy(\"date_built\").parquet(\"path/to/formatted_parquet_data\")"
      ],
      "metadata": {
        "id": "zvnYEn6PiP2m"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Create a temporary table for the parquet data\n",
        "parquet_df = spark.read.parquet(\"path/to/formatted_parquet_data\")\n",
        "parquet_df.createOrReplaceTempView(\"parquet_data\")\n"
      ],
      "metadata": {
        "id": "YwQz2473i_q9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. Run the query on the parquet temporary table and measure runtime\n",
        "start_time_parquet = time.time()\n",
        "result_parquet = spark.sql(query6)\n",
        "end_time_parquet = time.time()\n",
        "runtime_parquet = end_time_parquet - start_time_parquet\n",
        "runtime_parquet_formatted = \"{:.2f}\".format(runtime_parquet)\n",
        "print(f\"Runtime for parquet query: {runtime_parquet_formatted} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAQiowyI0GmJ",
        "outputId": "3b49593a-a4d7-4f5b-f158-058cd7b19fe9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Runtime for parquet query: 0.06 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. Uncache the home_sales temporary table and verify\n",
        "spark.catalog.uncacheTable(\"home_sales\")\n",
        "if spark.catalog.isCached(\"home_sales\"):\n",
        "    print(\"home_sales table is still cached.\")\n",
        "else:\n",
        "    print(\"home_sales table is uncached.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoRZTZZL0f2W",
        "outputId": "2ccefd7d-1423-48a7-8792-ca24ef85c275"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "home_sales table is uncached.\n"
          ]
        }
      ]
    }
  ]
}